{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline\n",
    "custom_style = {'axes.labelcolor': 'white',\n",
    "                'xtick.color': 'white',\n",
    "                'ytick.color': 'white'}\n",
    "sns.set_style(\"darkgrid\", rc=custom_style)\n",
    "sns.set_context(\"notebook\")\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams[\"font.size\"] = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learnによるLogistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=100.0, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=1, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "acc = (y_pred == y_test).sum() / len(y_test)\n",
    "print('accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PytorchによるLogistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = np.unique(y_train).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.reshape(-1,1)\n",
    "# y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Linear(in_features=X_train.shape[1], out_features=num_class)\n",
    "## 勾配降下法のオプティマイザーに上で定義したネットワークのパラメータを渡す\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)\n",
    "## MSE(mean squared error) lossクラス\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    inputs = torch.from_numpy(X_train).float()\n",
    "    targets = torch.from_numpy(y_train).long()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(X_test, y_test):\n",
    "    inputs = torch.from_numpy(X_test).float()\n",
    "    targets = torch.from_numpy(y_test).long() ## vectorで渡す必要がある\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    val_loss = loss_fn(outputs, targets)\n",
    "    \n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct = (predicted == targets).sum().item()\n",
    "    val_acc = float(correct) / targets.size(0)\n",
    "    \n",
    "    return val_loss.item(), val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epech 0, loss: 1.4995, val_loss: 1.5135, val_acc: 0.088889\n",
      "epech 100, loss: 0.7208, val_loss: 0.7576, val_acc: 0.666667\n",
      "epech 200, loss: 0.5478, val_loss: 0.5927, val_acc: 0.755556\n",
      "epech 300, loss: 0.4737, val_loss: 0.5248, val_acc: 0.777778\n",
      "epech 400, loss: 0.4305, val_loss: 0.4864, val_acc: 0.800000\n",
      "epech 500, loss: 0.4014, val_loss: 0.4608, val_acc: 0.800000\n",
      "epech 600, loss: 0.3799, val_loss: 0.4421, val_acc: 0.800000\n",
      "epech 700, loss: 0.3632, val_loss: 0.4274, val_acc: 0.800000\n",
      "epech 800, loss: 0.3495, val_loss: 0.4151, val_acc: 0.800000\n",
      "epech 900, loss: 0.3379, val_loss: 0.4045, val_acc: 0.800000\n",
      "epech 1000, loss: 0.3278, val_loss: 0.3950, val_acc: 0.800000\n",
      "epech 1100, loss: 0.3190, val_loss: 0.3864, val_acc: 0.800000\n",
      "epech 1200, loss: 0.3109, val_loss: 0.3784, val_acc: 0.822222\n",
      "epech 1300, loss: 0.3036, val_loss: 0.3709, val_acc: 0.822222\n",
      "epech 1400, loss: 0.2969, val_loss: 0.3638, val_acc: 0.822222\n",
      "epech 1500, loss: 0.2907, val_loss: 0.3570, val_acc: 0.822222\n",
      "epech 1600, loss: 0.2849, val_loss: 0.3506, val_acc: 0.844444\n",
      "epech 1700, loss: 0.2794, val_loss: 0.3444, val_acc: 0.844444\n",
      "epech 1800, loss: 0.2742, val_loss: 0.3385, val_acc: 0.844444\n",
      "epech 1900, loss: 0.2693, val_loss: 0.3327, val_acc: 0.844444\n",
      "epech 2000, loss: 0.2647, val_loss: 0.3272, val_acc: 0.844444\n",
      "epech 2100, loss: 0.2602, val_loss: 0.3219, val_acc: 0.844444\n",
      "epech 2200, loss: 0.2560, val_loss: 0.3168, val_acc: 0.844444\n",
      "epech 2300, loss: 0.2520, val_loss: 0.3118, val_acc: 0.844444\n",
      "epech 2400, loss: 0.2481, val_loss: 0.3070, val_acc: 0.844444\n",
      "epech 2500, loss: 0.2444, val_loss: 0.3023, val_acc: 0.844444\n",
      "epech 2600, loss: 0.2408, val_loss: 0.2978, val_acc: 0.844444\n",
      "epech 2700, loss: 0.2374, val_loss: 0.2934, val_acc: 0.844444\n",
      "epech 2800, loss: 0.2341, val_loss: 0.2892, val_acc: 0.844444\n",
      "epech 2900, loss: 0.2309, val_loss: 0.2851, val_acc: 0.844444\n",
      "epech 3000, loss: 0.2279, val_loss: 0.2811, val_acc: 0.866667\n",
      "epech 3100, loss: 0.2249, val_loss: 0.2772, val_acc: 0.866667\n",
      "epech 3200, loss: 0.2220, val_loss: 0.2735, val_acc: 0.866667\n",
      "epech 3300, loss: 0.2193, val_loss: 0.2699, val_acc: 0.866667\n",
      "epech 3400, loss: 0.2166, val_loss: 0.2663, val_acc: 0.866667\n",
      "epech 3500, loss: 0.2140, val_loss: 0.2629, val_acc: 0.866667\n",
      "epech 3600, loss: 0.2115, val_loss: 0.2596, val_acc: 0.888889\n",
      "epech 3700, loss: 0.2091, val_loss: 0.2563, val_acc: 0.888889\n",
      "epech 3800, loss: 0.2068, val_loss: 0.2532, val_acc: 0.888889\n",
      "epech 3900, loss: 0.2045, val_loss: 0.2502, val_acc: 0.911111\n",
      "epech 4000, loss: 0.2023, val_loss: 0.2472, val_acc: 0.911111\n",
      "epech 4100, loss: 0.2002, val_loss: 0.2443, val_acc: 0.911111\n",
      "epech 4200, loss: 0.1981, val_loss: 0.2415, val_acc: 0.911111\n",
      "epech 4300, loss: 0.1961, val_loss: 0.2388, val_acc: 0.911111\n",
      "epech 4400, loss: 0.1941, val_loss: 0.2361, val_acc: 0.911111\n",
      "epech 4500, loss: 0.1922, val_loss: 0.2335, val_acc: 0.911111\n",
      "epech 4600, loss: 0.1903, val_loss: 0.2310, val_acc: 0.911111\n",
      "epech 4700, loss: 0.1885, val_loss: 0.2285, val_acc: 0.911111\n",
      "epech 4800, loss: 0.1868, val_loss: 0.2261, val_acc: 0.933333\n",
      "epech 4900, loss: 0.1851, val_loss: 0.2238, val_acc: 0.955556\n",
      "epech 5000, loss: 0.1834, val_loss: 0.2215, val_acc: 0.955556\n",
      "epech 5100, loss: 0.1818, val_loss: 0.2193, val_acc: 0.955556\n",
      "epech 5200, loss: 0.1802, val_loss: 0.2172, val_acc: 0.955556\n",
      "epech 5300, loss: 0.1787, val_loss: 0.2150, val_acc: 0.977778\n",
      "epech 5400, loss: 0.1772, val_loss: 0.2130, val_acc: 0.977778\n",
      "epech 5500, loss: 0.1757, val_loss: 0.2110, val_acc: 0.977778\n",
      "epech 5600, loss: 0.1743, val_loss: 0.2090, val_acc: 0.977778\n",
      "epech 5700, loss: 0.1729, val_loss: 0.2071, val_acc: 0.977778\n",
      "epech 5800, loss: 0.1715, val_loss: 0.2052, val_acc: 0.977778\n",
      "epech 5900, loss: 0.1702, val_loss: 0.2034, val_acc: 0.977778\n",
      "epech 6000, loss: 0.1689, val_loss: 0.2016, val_acc: 0.977778\n",
      "epech 6100, loss: 0.1676, val_loss: 0.1999, val_acc: 0.977778\n",
      "epech 6200, loss: 0.1664, val_loss: 0.1981, val_acc: 0.977778\n",
      "epech 6300, loss: 0.1652, val_loss: 0.1965, val_acc: 0.977778\n",
      "epech 6400, loss: 0.1640, val_loss: 0.1948, val_acc: 0.977778\n",
      "epech 6500, loss: 0.1629, val_loss: 0.1932, val_acc: 0.977778\n",
      "epech 6600, loss: 0.1617, val_loss: 0.1917, val_acc: 0.977778\n",
      "epech 6700, loss: 0.1606, val_loss: 0.1901, val_acc: 0.977778\n",
      "epech 6800, loss: 0.1595, val_loss: 0.1886, val_acc: 0.977778\n",
      "epech 6900, loss: 0.1585, val_loss: 0.1871, val_acc: 0.977778\n",
      "epech 7000, loss: 0.1574, val_loss: 0.1857, val_acc: 0.977778\n",
      "epech 7100, loss: 0.1564, val_loss: 0.1843, val_acc: 0.977778\n",
      "epech 7200, loss: 0.1554, val_loss: 0.1829, val_acc: 0.977778\n",
      "epech 7300, loss: 0.1544, val_loss: 0.1815, val_acc: 0.977778\n",
      "epech 7400, loss: 0.1535, val_loss: 0.1802, val_acc: 0.977778\n",
      "epech 7500, loss: 0.1525, val_loss: 0.1789, val_acc: 0.977778\n",
      "epech 7600, loss: 0.1516, val_loss: 0.1776, val_acc: 0.977778\n",
      "epech 7700, loss: 0.1507, val_loss: 0.1764, val_acc: 0.977778\n",
      "epech 7800, loss: 0.1498, val_loss: 0.1751, val_acc: 0.977778\n",
      "epech 7900, loss: 0.1489, val_loss: 0.1739, val_acc: 0.977778\n",
      "epech 8000, loss: 0.1481, val_loss: 0.1727, val_acc: 0.977778\n",
      "epech 8100, loss: 0.1473, val_loss: 0.1716, val_acc: 0.977778\n",
      "epech 8200, loss: 0.1464, val_loss: 0.1704, val_acc: 0.977778\n",
      "epech 8300, loss: 0.1456, val_loss: 0.1693, val_acc: 0.977778\n",
      "epech 8400, loss: 0.1448, val_loss: 0.1682, val_acc: 0.977778\n",
      "epech 8500, loss: 0.1441, val_loss: 0.1671, val_acc: 0.977778\n",
      "epech 8600, loss: 0.1433, val_loss: 0.1660, val_acc: 0.977778\n",
      "epech 8700, loss: 0.1425, val_loss: 0.1650, val_acc: 0.977778\n",
      "epech 8800, loss: 0.1418, val_loss: 0.1640, val_acc: 0.977778\n",
      "epech 8900, loss: 0.1411, val_loss: 0.1630, val_acc: 0.977778\n",
      "epech 9000, loss: 0.1404, val_loss: 0.1620, val_acc: 0.977778\n",
      "epech 9100, loss: 0.1397, val_loss: 0.1610, val_acc: 0.977778\n",
      "epech 9200, loss: 0.1390, val_loss: 0.1600, val_acc: 0.977778\n",
      "epech 9300, loss: 0.1383, val_loss: 0.1591, val_acc: 0.977778\n",
      "epech 9400, loss: 0.1376, val_loss: 0.1581, val_acc: 0.977778\n",
      "epech 9500, loss: 0.1370, val_loss: 0.1572, val_acc: 0.955556\n",
      "epech 9600, loss: 0.1363, val_loss: 0.1563, val_acc: 0.955556\n",
      "epech 9700, loss: 0.1357, val_loss: 0.1554, val_acc: 0.955556\n",
      "epech 9800, loss: 0.1351, val_loss: 0.1546, val_acc: 0.955556\n",
      "epech 9900, loss: 0.1344, val_loss: 0.1537, val_acc: 0.955556\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "val_acces = []\n",
    "epoch = 10000\n",
    "for e in range(epoch):\n",
    "    param = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(param)\n",
    "    X_train = X_train[param]\n",
    "    y_train = y_train[param]\n",
    "    \n",
    "    loss = train(X_train, y_train)\n",
    "    val_loss, val_acc = valid(X_test, y_test)\n",
    "    \n",
    "    if e % 100 == 0:\n",
    "        print('epech {:d}, loss: {:.4f}, val_loss: {:.4f}, val_acc: {:4f}'.format(e, loss, val_loss, val_acc))\n",
    "        \n",
    "    losses.append(loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_acces.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a24d04f28>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_acces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
